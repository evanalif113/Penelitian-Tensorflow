{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "dd6daebe",
        "execution_start": 1764723105927,
        "execution_millis": 0,
        "execution_context_id": "de379ba4-59fe-4fa9-ac58-e714b16b53f5",
        "cell_id": "17538fa78c2d4eb2bf19fac9de810834",
        "deepnote_cell_type": "code"
      },
      "source": "import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nimport matplotlib.animation as animation\nimport datetime\nimport seaborn as sns\nimport missingno as msno\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom datetime import datetime  # Untuk konversi timestamp ke human-readable\nsns.set_theme(style=\"whitegrid\")\n%matplotlib inline ",
      "block_group": "c08f691f182948beb5fdc368b0d2fd79",
      "execution_count": 19,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "b4294b0b",
        "execution_start": 1764722990389,
        "execution_millis": 8939,
        "execution_context_id": "de379ba4-59fe-4fa9-ac58-e714b16b53f5",
        "cell_id": "9f6bd5894cae422ead1e28f117554d9c",
        "deepnote_cell_type": "code"
      },
      "source": "# ==========================================\n# 1. KONFIGURASI & LOAD DATA\n# ==========================================\nFOLDER_DATA = \"/work/open_meteo_climate\" # Sesuaikan dengan folder Anda\nNAMA_FILE = \"kebumen_75tahun_lengkap.csv\"\nPATH_FILE = os.path.join(FOLDER_DATA, NAMA_FILE)\n\ndef load_data(filepath):\n    if not os.path.exists(filepath):\n        print(f\"âŒ File {filepath} tidak ditemukan.\")\n        return None\n    # Baca data & parsing tanggal\n    df = pd.read_csv(filepath, index_col='date', parse_dates=True)\n    df.index = pd.to_datetime(df.index, utc=True).tz_convert('Asia/Jakarta').tz_localize(None)\n    df = df.sort_index()\n    return df\n\n# Load Data\ndf = load_data(PATH_FILE)\n\n# (Opsional) Kita ambil data 5 tahun terakhir saja biar training cepat untuk demo\n# Kalau komputer kuat, bisa pakai semua data.\ndf_model = df.loc['2020':] \n\nprint(f\"âœ… Data Siap: {df_model.shape}\")\nprint(df_model.head())",
      "block_group": "8ab4478fdf014ab78885e7255b2d5c13",
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "text": "âœ… Data Siap: (51864, 8)\n                     temperature  humidity   dewpoint  rain_mm  wind_speed  \\\ndate                                                                         \n2020-01-01 00:00:00       25.188  94.19893  24.188000      0.2    4.104631   \n2020-01-01 01:00:00       24.888  94.46978  23.938000      1.8    9.178235   \n2020-01-01 02:00:00       24.938  94.75593  24.038000      0.8    6.034700   \n2020-01-01 03:00:00       25.088  93.06975  23.888000      1.9    3.259939   \n2020-01-01 04:00:00       24.938  94.47180  23.987999      7.5    3.877318   \n\n                     wind_direction    pressure  weather_code  \ndate                                                           \n2020-01-01 00:00:00       307.87503  1008.30444          51.0  \n2020-01-01 01:00:00       334.44006  1008.10260          61.0  \n2020-01-01 02:00:00       287.35410  1007.60400          53.0  \n2020-01-01 03:00:00       276.34010  1007.60500          61.0  \n2020-01-01 04:00:00       248.19853  1007.40450          63.0  \n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "cde5387b",
        "execution_start": 1764723013286,
        "execution_millis": 1,
        "execution_context_id": "de379ba4-59fe-4fa9-ac58-e714b16b53f5",
        "cell_id": "fc6e76d6c92e494f9a617f7aa0e06835",
        "deepnote_cell_type": "code"
      },
      "source": "# ==========================================\n# 2. PRE-PROCESSING (SCALING)\n# ==========================================\n# Kita akan gunakan Multivariate Input:\n# Menggunakan [Suhu, Kelembapan, Hujan, Angin, Tekanan] untuk memprediksi [SUHU] besok.\n\n# Fitur yang dipakai\nfeatures = ['temperature', 'humidity', 'rain_mm', 'wind_speed', 'pressure']\ntarget = 'temperature' # Kita coba prediksi SUHU dulu (paling mudah divalidasi)\n\n# 1. Handling Missing Values (Interpolasi)\ndf_model = df_model[features].interpolate(method='time')\n\n# 2. Normalisasi (MinMax Scaler) -> Wajib buat LSTM agar range 0-1\nscaler = MinMaxScaler(feature_range=(0, 1))\nscaled_data = scaler.fit_transform(df_model)\n\n# Buat DataFrame baru hasil scaling\ndf_scaled = pd.DataFrame(scaled_data, columns=features, index=df_model.index)",
      "block_group": "998581e390aa412ca44361591c3cbf89",
      "execution_count": 7,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "f19622f3",
        "execution_start": 1764723038425,
        "execution_millis": 2914,
        "execution_context_id": "de379ba4-59fe-4fa9-ac58-e714b16b53f5",
        "cell_id": "297f0fa059dc4d6bbc92d345d043aeed",
        "deepnote_cell_type": "code"
      },
      "source": "# ==========================================\n# 3. MEMBUAT DATASET TIME-SERIES (SLIDING WINDOW)\n# ==========================================\ndef create_dataset(X, y, time_steps=1):\n    Xs, ys = [], []\n    for i in range(len(X) - time_steps):\n        v = X.iloc[i:(i + time_steps)].values\n        Xs.append(v)\n        # Targetnya adalah nilai langkah berikutnya\n        ys.append(y.iloc[i + time_steps])\n    return np.array(Xs), np.array(ys)\n\n# KONFIGURASI WINDOW\nTIME_STEPS = 24  # Gunakan data 24 jam terakhir...\n# ...untuk memprediksi suhu jam ke-25.\n\nX = df_scaled[features] # Input (Semua Fitur)\ny = df_scaled[target]   # Output (Suhu saja)\n\nX_latih, y_latih = create_dataset(X, y, TIME_STEPS)\n\nprint(f\"Bentuk Input X: {X_latih.shape}  (Sampel, TimeSteps, Fitur)\")\nprint(f\"Bentuk Target y: {y_latih.shape}\")",
      "block_group": "562b20f1ad304ea492347eeb02249a23",
      "execution_count": 10,
      "outputs": [
        {
          "name": "stdout",
          "text": "Bentuk Input X: (51840, 24, 5)  (Sampel, TimeSteps, Fitur)\nBentuk Target y: (51840,)\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "e1c5e353",
        "execution_start": 1764723057290,
        "execution_millis": 2,
        "execution_context_id": "de379ba4-59fe-4fa9-ac58-e714b16b53f5",
        "cell_id": "d365a9b66eaa4533a0cb51a7ab7c3078",
        "deepnote_cell_type": "code"
      },
      "source": "# ==========================================\n# 4. SPLITTING DATA (TRAIN vs TEST)\n# ==========================================\n# Jangan diacak (shuffle) karena ini data urut waktu!\ntrain_size = int(len(X_latih) * 0.8)\nX_train, y_train = X_latih[:train_size], y_latih[:train_size]\nX_test, y_test = X_latih[train_size:], y_latih[train_size:]\n\nprint(f\"Data Training: {len(X_train)}\")\nprint(f\"Data Testing : {len(X_test)}\")",
      "block_group": "c9f4c7320dc44076bb211a256d2708aa",
      "execution_count": 13,
      "outputs": [
        {
          "name": "stdout",
          "text": "Data Training: 41472\nData Testing : 10368\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "644a5189",
        "execution_start": 1764723111971,
        "execution_millis": 976,
        "execution_context_id": "de379ba4-59fe-4fa9-ac58-e714b16b53f5",
        "cell_id": "477eac6df48d493d8ca7ac6256775c21",
        "deepnote_cell_type": "code"
      },
      "source": "# ==========================================\n# 5. MEMBANGUN MODEL LSTM\n# ==========================================\nmodel = Sequential()\n\n# Layer LSTM 1\nmodel.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\nmodel.add(Dropout(0.2)) # Biar gak overfitting\n\n# Layer LSTM 2\nmodel.add(LSTM(units=50, return_sequences=False))\nmodel.add(Dropout(0.2))\n\n# Output Layer (1 neuron karena prediksi suhu)\nmodel.add(Dense(1))\n\n# Compile\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\nmodel.summary()",
      "block_group": "639bc131d3e64537b61520394b910a14",
      "execution_count": 22,
      "outputs": [
        {
          "name": "stdout",
          "text": "Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n lstm (LSTM)                 (None, 24, 50)            11200     \n                                                                 \n dropout (Dropout)           (None, 24, 50)            0         \n                                                                 \n lstm_1 (LSTM)               (None, 50)                20200     \n                                                                 \n dropout_1 (Dropout)         (None, 50)                0         \n                                                                 \n dense (Dense)               (None, 1)                 51        \n                                                                 \n=================================================================\nTotal params: 31451 (122.86 KB)\nTrainable params: 31451 (122.86 KB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "source_hash": "4a7f8",
        "execution_start": 1764723138286,
        "execution_context_id": "de379ba4-59fe-4fa9-ac58-e714b16b53f5",
        "cell_id": "0593784260f945b183a7b2ec6902a2f2",
        "deepnote_cell_type": "code"
      },
      "source": "# ==========================================\n# 6. TRAINING MODEL\n# ==========================================\n# Early Stopping: Berhenti kalau tidak ada perbaikan error\nearly_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\nhistory = model.fit(\n    X_train, y_train,\n    epochs=20,           # Jumlah putaran belajar (bisa dinaikkan jadi 50/100)\n    batch_size=32,       # Ukuran batch\n    validation_split=0.1,\n    callbacks=[early_stop],\n    verbose=1\n)\n\n# Plot Loss History\nplt.figure(figsize=(10, 5))\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Grafik Error Training Model')\nplt.xlabel('Epoch')\nplt.ylabel('Loss (MSE)')\nplt.legend()\nplt.show()",
      "block_group": "86c345df8caa42bca116d86e9bcf1a38",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/20\n1167/1167 [==============================] - 43s 34ms/step - loss: 0.0074 - val_loss: 0.0022\nEpoch 2/20\n1167/1167 [==============================] - 43s 37ms/step - loss: 0.0029 - val_loss: 0.0015\nEpoch 3/20\n1167/1167 [==============================] - 37s 32ms/step - loss: 0.0019 - val_loss: 9.2849e-04\nEpoch 4/20\n1167/1167 [==============================] - 34s 29ms/step - loss: 0.0015 - val_loss: 8.4306e-04\nEpoch 5/20\n1167/1167 [==============================] - 30s 26ms/step - loss: 0.0012 - val_loss: 7.4584e-04\nEpoch 6/20\n1167/1167 [==============================] - 29s 25ms/step - loss: 0.0010 - val_loss: 8.3109e-04\nEpoch 7/20\n 349/1167 [=======>......................] - ETA: 19s - loss: 9.5060e-04",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "19e587ea74f644f090711edec560cb0c",
        "deepnote_cell_type": "code"
      },
      "source": "# ==========================================\n# 7. EVALUASI & PREDIKSI\n# ==========================================\n# Prediksi data test\ny_pred = model.predict(X_test)\n\n# Kembalikan ke skala asli (Inverse Transform)\n# Karena scaler kita punya 5 kolom, kita harus bikin dummy array biar pas strukturnya\ndef inverse_transform_target(pred_value, scaler):\n    # Buat array kosong seukuran fitur\n    dummy = np.zeros((len(pred_value), len(features)))\n    # Isi kolom target (kolom ke-0 adalah temperature sesuai urutan 'features' di atas)\n    dummy[:, 0] = pred_value.flatten()\n    # Inverse\n    inversed = scaler.inverse_transform(dummy)\n    return inversed[:, 0]\n\ny_test_inv = inverse_transform_target(y_test.reshape(-1, 1), scaler)\ny_pred_inv = inverse_transform_target(y_pred, scaler)\n\n# Plot Hasil Prediksi vs Asli\nplt.figure(figsize=(15, 6))\n# Ambil 200 jam terakhir biar kelihatan detailnya\nrange_plot = 200 \nplt.plot(y_test_inv[:range_plot], label='Suhu Asli (Aktual)', color='blue')\nplt.plot(y_pred_inv[:range_plot], label='Prediksi LSTM', color='red', linestyle='--')\nplt.title(f'Prediksi Suhu Cuaca Kebumen (Comparasi {range_plot} Jam Pertama Data Test)')\nplt.xlabel('Jam ke-')\nplt.ylabel('Suhu (Â°C)')\nplt.legend()\nplt.show()\n\n# Hitung Error (RMSE)\nrmse = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))\nprint(f\"ðŸ“Š Root Mean Squared Error (RMSE): {rmse:.2f} Â°C\")\nprint(f\"   (Artinya prediksi meleset rata-rata sekitar {rmse:.2f} derajat)\")",
      "block_group": "d1f4499fa1a9414aa09c77965550d8a7",
      "execution_count": null,
      "outputs": [],
      "outputs_reference": null,
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=672c3bf7-b636-46e8-b7c0-4f6feec29313' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "deepnote_notebook_id": "ceeb7584b0344470b6f11197436fe13b"
  }
}